{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The FoLiA library pynlpl.formats.folia is being used but this version is now deprecated and is replaced by FoLiAPy (pip install folia), see https://github.com/proycon/foliapy. Please update your software if you are a developer, if you are an end-user you can safely ignore this message.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from pynlpl.formats import folia\n",
    "# from folia import main as folia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_train_path = '../corpus/Token/semantic_train.txt'\n",
    "semantic_valid_path = '../corpus/Token/semantic_dev.txt'\n",
    "semantic_test_path = '../corpus/Token/semantic_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder='/home/aorus/workspaces/simge/Master_Thesis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_labels = ['group_clash', 'demonst', 'ind_act', 'arm_mil', 'elec_pol', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_semantic_data(semantic_path):\n",
    "    art_id = 1\n",
    "    sent_num = 1\n",
    "    articles = []\n",
    "    art = {\n",
    "        'id': 'a.' + str(art_id),\n",
    "        'sentences': []\n",
    "    }\n",
    "    sent = {\n",
    "        'sent_num': str(art_id) + '-' + str(sent_num),\n",
    "        'sentence': [],\n",
    "        'label': []\n",
    "    }\n",
    "\n",
    "    with open(semantic_path, 'r', encoding='utf-8') as f:\n",
    "\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            line_ = line.strip().split('\\t')\n",
    "\n",
    "            if (line_[0] == '' and (i != len(lines)-1)) or (i==0 and line_[0]=='SAMPLE_START'):\n",
    "                continue\n",
    "\n",
    "            elif line_[0] == 'SAMPLE_START' or i == len(lines)-1:\n",
    "                # add the last sentence\n",
    "                unique_labels = list({label[2:] for label in sent['label'] if label != 'O'})\n",
    "                sent['label'] = ['O'] if not unique_labels else unique_labels\n",
    "                art['sentences'].append(sent)\n",
    "                articles.append(art)\n",
    "                art_id = art_id + 1\n",
    "                sent_num = 1\n",
    "\n",
    "                art = {\n",
    "                    'id': 'a.' + str(art_id),\n",
    "                    'sentences': []\n",
    "                }\n",
    "                sent = {\n",
    "                    'sent_num': str(art_id) + '-' + str(sent_num),\n",
    "                    'sentence': [],\n",
    "                    'label': []\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                if line_[0] == '[SEP]':\n",
    "                    unique_labels = list({label[2:] for label in sent['label'] if label != 'O'})\n",
    "                    sent['label'] = ['O'] if not unique_labels else unique_labels\n",
    "                    art['sentences'].append(sent)\n",
    "                    sent_num = sent_num + 1\n",
    "                    sent = {\n",
    "                        'sent_num': str(art_id) + '-' + str(sent_num),\n",
    "                        'sentence': [],\n",
    "                        'label': []\n",
    "                    }\n",
    "\n",
    "                else:\n",
    "                    sent['sentence'].append(line_[0])\n",
    "                    sent['label'].append(line_[1])\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_articles = prepare_semantic_data(semantic_train_path)\n",
    "valid_articles = prepare_semantic_data(semantic_valid_path)\n",
    "test_articles = prepare_semantic_data(semantic_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_semantic = {\n",
    "    'train': train_articles,\n",
    "    'valid': valid_articles,\n",
    "    'test': test_articles\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/semantic_all_data.json', 'w') as jf:\n",
    "    json.dump(all_semantic, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/semantic_all_data.json', 'r') as jf:\n",
    "    jj = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'valid', 'test'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_label_counts = []\n",
    "multilabel = []\n",
    "for i in jj['train']+jj['valid']+jj['test']:\n",
    "    for j in i['sentences']:\n",
    "        if len(j['label']) < 2:\n",
    "            semantic_label_counts += j['label']\n",
    "        else:\n",
    "            multilabel.append(j['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['group_clash', 'arm_mil'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['elec_pol', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['group_clash', 'arm_mil'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['group_clash', 'arm_mil'],\n",
       " ['group_clash', 'arm_mil'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['group_clash', 'arm_mil'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['elec_pol', 'demonst'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'other'],\n",
       " ['demonst', 'other'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['ind_act', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['group_clash', 'arm_mil'],\n",
       " ['elec_pol', 'demonst'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['elec_pol', 'demonst'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'group_clash'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'ind_act'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil'],\n",
       " ['demonst', 'arm_mil']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'group_clash': 388,\n",
       "         'O': 5134,\n",
       "         'demonst': 1160,\n",
       "         'arm_mil': 507,\n",
       "         'ind_act': 290,\n",
       "         'elec_pol': 51,\n",
       "         'other': 15})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(semantic_label_counts)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['O'] = counts['O'] + counts['other']\n",
    "counts.pop('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'group_clash': 388,\n",
       " 'O': 5149,\n",
       " 'demonst': 1160,\n",
       " 'arm_mil': 507,\n",
       " 'ind_act': 290,\n",
       " 'elec_pol': 51}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_clash 0.05142478462557985\n",
      "O 0.6824387011265739\n",
      "demonst 0.15374420145791914\n",
      "arm_mil 0.06719681908548708\n",
      "ind_act 0.038436050364479786\n",
      "elec_pol 0.006759443339960238\n"
     ]
    }
   ],
   "source": [
    "for k,v in counts.items():\n",
    "    print(k, v/sum([y for y in counts.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['group_clash'] / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 7545, 2: 92, 3: 1})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(label_nums)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "388\n",
    "'O': 5149,\n",
    "'demonst': 1160,\n",
    "'arm_mil': 507,\n",
    "'ind_act': 290,\n",
    "'elec_pol': 51,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "388 / 5149+1160+507+290"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
