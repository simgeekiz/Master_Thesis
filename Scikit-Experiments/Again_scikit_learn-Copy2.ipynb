{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, metadata = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_stopwords = [str(i) for i in range(10001)] + ['0'+str(i) for i in range(100)] + ['000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'f1_macro'\n",
    "n_jobs=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_sents = np.array([sentence['sentence']\n",
    "     for article in train_data\n",
    "     for sentence in article['sentences']])\n",
    "y_tra = np.array([sentence['label'] for article in train_data for sentence in article['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_sents = np.array([sentence['sentence']\n",
    "     for article in (train_data + valid_data)\n",
    "     for sentence in article['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_opt = np.array([sentence['label'] for article in (train_data + valid_data) for sentence in article['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents =  np.array([sentence['sentence']\n",
    "     for article in test_data\n",
    "     for sentence in article['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([sentence['label'] for article in test_data for sentence in article['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 3582, 441, 441)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tra_sents), len(y_tra), len(test_sents), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that best TFIDFVectorizer features are as listed below;\n",
    "    min_df: 0.001\n",
    "    max_df: 0.6\n",
    "    stop_words: num_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.001, max_df=0.12, stop_words=number_stopwords)\n",
    "tfidf_vectors = vectorizer.fit_transform(opt_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_vectors = vectorizer.transform(tra_sents)\n",
    "test_vectors = vectorizer.transform(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3010"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Feature Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_path = 'Data/features_mindf_0_001_maxdf_0_12_number_stopwords.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(feature_path, 'wb') as file_:\n",
    "    pickle.dump(tfidf_vectors, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3981, 3010)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training\n",
    "- With hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results = {}\n",
    "opt_results_path = 'Results/results_050919_tfidf_only_mindf_001_maxdf_0_12_numberstoplwords.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score\n",
      "0.757883389796395\n",
      "Best Params\n",
      "{'max_depth': None, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 150}\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "# Decision Tree\n",
    "params = {\n",
    "    'max_depth': [None] + [*range(15, 35, 5)],\n",
    "    'min_samples_split': [*range(50, 200, 20)],\n",
    "    'min_samples_leaf': [*range(3, 14, 2)],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "dt_clf = GridSearchCV(classifier, params, cv=5, refit=False, scoring=scoring, n_jobs=n_jobs)\n",
    "dt_clf = dt_clf.fit(tfidf_vectors, y_opt)\n",
    "\n",
    "# print('Best Estimator')\n",
    "# print(dt_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(dt_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(dt_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='gini', **dt_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=150,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT.fit(tra_vectors, y_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DT.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['DecisionTree'] = {}\n",
    "opt_results['DecisionTree']['GridSearchCV'] = dt_clf\n",
    "opt_results['DecisionTree']['classif_report'] = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       325\n",
      "           1       0.79      0.60      0.68       116\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       441\n",
      "   macro avg       0.83      0.77      0.79       441\n",
      "weighted avg       0.85      0.85      0.85       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(3010*0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(criterion='gini')\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [50] + [*range(100, 1000, 100)], \n",
    "    'max_depth': [None] + [*range(65, 120, 5)], \n",
    "    'min_samples_split': [10, 20, 30, 40, 45, 50, 100, 120, 150],\n",
    "    'max_features': ['sqrt', 'log2', int(3010*0.1), int(3010*0.2), int(3010*0.3)],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "# params = {\n",
    "#     'n_estimators': [30, 50, 70, 100, 150], \n",
    "#     'max_depth': [None] + [*range(65, 120, 5)], \n",
    "#     'min_samples_split': [10, 20, 25, 30, 40, 45, 50, 100, 120, 150],\n",
    "#     'max_features': ['sqrt', 'log2'],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "rf_clf = GridSearchCV(classifier, params, cv=5, refit=False, scoring=scoring, n_jobs=n_jobs)\n",
    "rf_clf = rf_clf.fit(tfidf_vectors, y_opt)\n",
    "\n",
    "# print('Best Estimator')\n",
    "# print(rf_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(rf_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(rf_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(criterion='gini', **rf_clf.best_params_, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=602, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.fit(tra_vectors, y_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['RandomForest'] = {}\n",
    "opt_results['RandomForest']['GridSearchCV'] = rf_clf\n",
    "opt_results['RandomForest']['classif_report'] = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       325\n",
      "           1       0.75      0.56      0.64       116\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       441\n",
      "   macro avg       0.80      0.75      0.77       441\n",
      "weighted avg       0.83      0.83      0.83       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier =  SVC()\n",
    "params = {\n",
    "    'kernel': ('linear', 'poly', 'rbf', 'sigmoid'), \n",
    "    'C': [0.025, 0.25, 0.5, 1, 2, 3, 4, 5, 6, 7],\n",
    "}\n",
    "\n",
    "svc_clf = GridSearchCV(classifier, params, cv=5, refit=False, scoring=scoring, n_jobs=n_jobs)\n",
    "svc_clf = svc_clf.fit(tfidf_vectors, y_opt)\n",
    "\n",
    "# print('Best Estimator')\n",
    "# print(svc_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(svc_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(svc_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV = SVC(**svc_clf.best_params_, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV.fit(tra_vectors, y_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SV.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['SVC'] = {}\n",
    "opt_results['SVC']['GridSearchCV'] = svc_clf\n",
    "opt_results['SVC']['classif_report'] = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score\n",
      "0.7418806323618786\n",
      "Best Params\n",
      "{'learning_rate_init': 0.05, 'hidden_layer_sizes': 100, 'learning_rate': 'invscaling', 'max_iter': 50, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "classifier = MLPClassifier()\n",
    "\n",
    "params = {\n",
    "    'hidden_layer_sizes': [(20), (30), (50), (60), (70), (80), (100), (30,10), (50,10), (100,60), (60,20)], \n",
    "    'activation': ['relu'], \n",
    "    'learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.1, 0.01, 0.05, 0.001],\n",
    "    'max_iter': [50, 100, 200, 300, 400]\n",
    "}\n",
    "                        \n",
    "    \n",
    "#     params = {\n",
    "#     'hidden_layer_sizes': [(30), (50), (60), (70), (80), (100), (20)], \n",
    "#     'activation': ['relu'], \n",
    "#     'learning_rate': ['constant', 'adaptive'],\n",
    "#     'learning_rate_init': [0.01, 0.001, 0.1],\n",
    "#     'max_iter': [50, 100, 200, 300, 400, 500]\n",
    "# }\n",
    "                        \n",
    "mlp_clf = GridSearchCV(classifier, params, cv=5, refit=False, scoring=scoring, n_jobs=n_jobs)\n",
    "mlp_clf = mlp_clf.fit(tfidf_vectors, y_opt)\n",
    "\n",
    "\n",
    "\n",
    "# print('Best Estimator')\n",
    "# print(mlp_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(mlp_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(mlp_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML = MLPClassifier(**mlp_clf.best_params_, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=100, learning_rate='invscaling',\n",
       "              learning_rate_init=0.05, max_iter=50, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=0, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.fit(tra_vectors, y_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ML.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['MLP'] = {}\n",
    "opt_results['MLP']['GridSearchCV'] = mlp_clf\n",
    "opt_results['MLP']['classif_report'] = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       325\n",
      "           1       0.60      0.48      0.54       116\n",
      "\n",
      "    accuracy                           0.78       441\n",
      "   macro avg       0.71      0.68      0.70       441\n",
      "weighted avg       0.77      0.78      0.77       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(opt_results_path, 'rb') as file_:\n",
    "    opt_results = pickle.load(file_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DecisionTree', 'RandomForest'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
