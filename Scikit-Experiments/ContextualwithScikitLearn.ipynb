{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Optimized Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results = {}\n",
    "opt_results_path = 'Results/results_070919_tfidf_only_mindf_001_maxdf_0_12_numberstoplwords.pickle'\n",
    "contextual_classifiers_path = 'Results/results_110919_contextual_scikit.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['single_sentence', 'contextual_'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(contextual_classifiers_path, 'rb') as file_:\n",
    "    opt_results = pickle.load(file_)\n",
    "\n",
    "opt_results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, metadata = load_data(project_folder='./../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_stopwords = [str(i) for i in range(10001)] + ['0'+str(i) for i in range(100)] + ['000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'f1_macro'\n",
    "n_jobs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_sents = np.array([sentence['sentence']\n",
    "     for article in train_data\n",
    "     for sentence in article['sentences']])\n",
    "y_tra = np.array([sentence['label'] for article in train_data for sentence in article['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents =  np.array([sentence['sentence']\n",
    "     for article in test_data\n",
    "     for sentence in article['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([sentence['label'] for article in test_data for sentence in article['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 3582, 441, 441)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tra_sents), len(y_tra), len(test_sents), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contextual_sentences(data_, ww):\n",
    "\n",
    "    X = []\n",
    "    for article in data_:\n",
    "        sent_list = article['sentences']\n",
    "        for i, sentence in enumerate(sent_list):\n",
    "            merged_sents = [sent_list[i]['sentence'].replace('\\n', '').strip()]\n",
    "            for w in range(1, ww+1):\n",
    "                if i - w >= 0:\n",
    "                    merged_sents = [sent_list[i-w]['sentence'].replace('\\n', '').strip()] + merged_sents\n",
    "                if i + w < len(sent_list):\n",
    "                    merged_sents.append(sent_list[i+w]['sentence'].replace('\\n', '').strip())\n",
    "            X.append(' '.join(merged_sents))\n",
    "\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww=5\n",
    "X_tra = get_contextual_sentences(train_data, ww)\n",
    "X_val = get_contextual_sentences(valid_data, ww)\n",
    "X_test = get_contextual_sentences(test_data, ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_tra[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(data_, to_categorize):\n",
    "\n",
    "    y = np.array([sentence['label'] for article in data_ for sentence in article['sentences']])\n",
    "    if to_categorize:\n",
    "        y = to_categorical(y)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tra = get_y(train_data, False)\n",
    "y_val = get_y(valid_data, False)\n",
    "y_test = get_y(test_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra_val = np.concatenate((X_tra, X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that best TFIDFVectorizer features are as listed below;\n",
    "    min_df: 0.001\n",
    "    max_df: 0.6\n",
    "    stop_words: num_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.001, max_df=0.12, stop_words=number_stopwords)\n",
    "tfidf_vectors = vectorizer.fit_transform(X_tra_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_vectors = vectorizer.transform(X_tra)\n",
    "test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10642"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_path = 'Data/features_mindf_0_001_maxdf_0_12_number_stopwords.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(feature_path, 'wb') as file_:\n",
    "    pickle.dump(tfidf_vectors, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3981, 10642)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training\n",
    "- With hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score\n",
      "0.7580231977602293\n",
      "Best Params\n",
      "{'min_samples_split': 170, 'max_features': None, 'max_depth': None, 'min_samples_leaf': 5}\n"
     ]
    }
   ],
   "source": [
    "dt_clf = opt_results['single_sentence']['DecisionTree']['GridSearchCV']\n",
    "print('Best Score')\n",
    "print(dt_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(dt_clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='gini', **dt_clf.best_params_, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=170,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=5,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT.fit(tra_vectors, y_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DT.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82       381\n",
      "           1       0.22      0.43      0.30        60\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       441\n",
      "   macro avg       0.56      0.60      0.56       441\n",
      "weighted avg       0.80      0.72      0.75       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with window size ww=1 prevcurrnext\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83       363\n",
      "           1       0.34      0.50      0.40        78\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       441\n",
      "   macro avg       0.61      0.64      0.62       441\n",
      "weighted avg       0.78      0.74      0.76       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with window size ww=2 prevprevcurrnextnext\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83       360\n",
      "           1       0.34      0.49      0.41        81\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       441\n",
      "   macro avg       0.61      0.64      0.62       441\n",
      "weighted avg       0.78      0.73      0.75       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with window size ww=3 3prevcurr3next\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79       356\n",
      "           1       0.24      0.33      0.28        85\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       441\n",
      "   macro avg       0.53      0.54      0.53       441\n",
      "weighted avg       0.71      0.67      0.69       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with window size ww=5 ..5prevcurr5next..\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DecisionTree' not in opt_results['contextual_']:\n",
    "    opt_results['contextual_']['DecisionTree'] = {}\n",
    "opt_results['contextual_']['DecisionTree']['window_width_' + str(ww)] = {}\n",
    "opt_results['contextual_']['DecisionTree']['window_width_' + str(ww)]['classif_report'] = classification_report(y_pred, y_test)\n",
    "opt_results['contextual_']['DecisionTree']['window_width_' + str(ww)]['classifier'] = DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['window_width_1', 'window_width_2', 'window_width_3', 'window_width_5'])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_results['contextual_']['DecisionTree'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(contextual_classifiers_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(criterion='gini')\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [50] + [*range(100, 1000, 100)], \n",
    "    'max_depth': [None] + [*range(65, 120, 5)], \n",
    "    'min_samples_split': [10, 20, 30, 40, 45, 50, 100, 120, 150],\n",
    "    'max_features': ['sqrt', 'log2', int(3010*0.1), int(3010*0.2), int(3010*0.3)],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "# params = {\n",
    "#     'n_estimators': [30, 50, 70, 100, 150], \n",
    "#     'max_depth': [None] + [*range(65, 120, 5)], \n",
    "#     'min_samples_split': [10, 20, 25, 30, 40, 45, 50, 100, 120, 150],\n",
    "#     'max_features': ['sqrt', 'log2'],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "rf_clf = GridSearchCV(classifier, params, cv=5, refit=False, scoring=scoring, n_jobs=n_jobs)\n",
    "rf_clf = rf_clf.fit(tfidf_vectors, y_opt)\n",
    "\n",
    "# print('Best Estimator')\n",
    "# print(rf_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(rf_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(rf_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(criterion='gini', **rf_clf.best_params_, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.fit(tra_vectors, y_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['RandomForest'] = {}\n",
    "opt_results['RandomForest']['GridSearchCV'] = rf_clf\n",
    "opt_results['RandomForest']['classif_report'] = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
