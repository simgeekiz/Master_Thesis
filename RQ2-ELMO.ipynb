{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "* Butun makale yerine sliding window seklinde ver cumleleri (ekstra deney olarak) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: https://github.com/arunarn2/HierarchicalAttentionNetworks/blob/master/HierarchicalAttn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Model, Input\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Bidirectional, Lambda\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.callbacks import PlotCurves\n",
    "from src.custom_functions import f1_macro, f1_micro \n",
    "from src.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, metadata = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 60\n",
    "n_tags = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data_, max_len, n_tags, is_test=False):\n",
    "    \n",
    "    X = []\n",
    "    for article in data_:\n",
    "        new_seq = []\n",
    "        for i in range(max_len):\n",
    "            try:\n",
    "                new_seq.append(article['sentences'][i]['sentence'])\n",
    "            except:\n",
    "                new_seq.append(\"ENDPAD\")\n",
    "        X.append(new_seq)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    if not is_test: \n",
    "        y = [[sent['label'] for sent in article['sentences']] for article in data_]\n",
    "        y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=0)\n",
    "        y = np.array([[to_categorical(lab, num_classes=n_tags) for lab in sent] for sent in y])\n",
    "    else:\n",
    "        y = np.array([sent['label'] for article in data_ for sent in article['sentences']])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra, y_tra = split_data(train_data, max_len, n_tags, False)\n",
    "X_val, y_val = split_data(valid_data, max_len, n_tags, False)\n",
    "X_test, y_test = split_data(test_data, max_len, n_tags, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251, 60, 2), (32, 60, 2), (441,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tra.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra = X_tra[:250]\n",
    "y_tra = y_tra[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250, 60), numpy.ndarray)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tra.shape, type(X_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val[:32]\n",
    "y_val = y_val[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 60), (32, 60, 2), numpy.ndarray)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape, type(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELMoEmbedding(x):\n",
    "    embeds = []\n",
    "    for art in tf.unstack(tf.transpose(x, (1, 0))):\n",
    "        embeds.append(elmo(tf.squeeze(tf.cast(art, tf.string)), signature=\"default\", as_dict=True)[\"default\"])\n",
    "    return tf.stack(embeds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(max_len, n_tags):\n",
    "    \n",
    "    input_text = Input(shape=(max_len,), dtype=\"string\")\n",
    "    \n",
    "    embedding = Lambda(ELMoEmbedding, output_shape=(None, None, max_len, 1024))(input_text)\n",
    "    \n",
    "    dns = Dense(512, activation='relu')(embedding)\n",
    "    \n",
    "    dns = Dense(256, activation='relu')(dns)\n",
    "    \n",
    "    x = Bidirectional(LSTM(units=128, return_sequences=True,\n",
    "                           recurrent_dropout=0.2, dropout=0.2))(dns)\n",
    "\n",
    "    x_rnn = Bidirectional(LSTM(units=128, return_sequences=True,\n",
    "                               recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "\n",
    "    x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
    "\n",
    "    out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n",
    "    \n",
    "    return Model(input_text, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, None, 6 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, None, 6 524800      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, None, None, 6 131328      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 256)    394240      dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 256)    394240      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, 256)    0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 2)      514         add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,445,122\n",
      "Trainable params: 1,445,122\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_lstm_model(max_len, n_tags)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers[1:]]          # all layer outputs\n",
    "functor = K.function([inp, K.learning_phase()], outputs)   # evaluation function\n",
    "\n",
    "# Testing\n",
    "test = X_tra[:2]\n",
    "layer_outs = functor([test, 1.])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.layers[0:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for l in layer_outs:\n",
    "    print(l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 32 samples\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 213s 853ms/step - loss: 0.1333 - acc: 0.9430 - val_loss: 0.0687 - val_acc: 0.9682\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 141s 562ms/step - loss: 0.1001 - acc: 0.9557 - val_loss: 0.0698 - val_acc: 0.9693\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 140s 559ms/step - loss: 0.0863 - acc: 0.9626 - val_loss: 0.0669 - val_acc: 0.9719\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 141s 564ms/step - loss: 0.0734 - acc: 0.9691 - val_loss: 0.0664 - val_acc: 0.9724\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 140s 561ms/step - loss: 0.0663 - acc: 0.9718 - val_loss: 0.0724 - val_acc: 0.9688\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 141s 563ms/step - loss: 0.0490 - acc: 0.9808 - val_loss: 0.0918 - val_acc: 0.9651\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 140s 561ms/step - loss: 0.0353 - acc: 0.9865 - val_loss: 0.0976 - val_acc: 0.9687\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 140s 562ms/step - loss: 0.0237 - acc: 0.9905 - val_loss: 0.1225 - val_acc: 0.9641\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 140s 562ms/step - loss: 0.0195 - acc: 0.9929 - val_loss: 0.1298 - val_acc: 0.9682\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 141s 562ms/step - loss: 0.0148 - acc: 0.9947 - val_loss: 0.1264 - val_acc: 0.9698\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 141s 564ms/step - loss: 0.0121 - acc: 0.9961 - val_loss: 0.1457 - val_acc: 0.9615\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 140s 560ms/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.1609 - val_acc: 0.9672\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 141s 563ms/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.1531 - val_acc: 0.9661\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 141s 562ms/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.1900 - val_acc: 0.9667\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 141s 562ms/step - loss: 0.0150 - acc: 0.9956 - val_loss: 0.1750 - val_acc: 0.9599\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 142s 567ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.1981 - val_acc: 0.9656\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 140s 561ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.1958 - val_acc: 0.9708\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 141s 565ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.2353 - val_acc: 0.9625\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 141s 564ms/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.1745 - val_acc: 0.9667\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 141s 563ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.2904 - val_acc: 0.9568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f665fc6f748>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sequential Model\n",
    "model.fit(X_tra, y_tra, epochs=20, batch_size=2, validation_data=(X_val, y_val)) \n",
    "#            callbacks=[PlotCurves(model_name='elmo_sentence_sequence')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = model.predict(X_test, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = [[np.argmax(lab) for lab in art] for art in model_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_unpad = []\n",
    "for ai, art in enumerate(X_test):\n",
    "    for si, sent in enumerate(art):\n",
    "        if sent != 'ENDPAD':\n",
    "            y_preds_unpad.append(y_preds[ai][si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.84       325\n",
      "           1       0.55      0.75      0.64       116\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       441\n",
      "   macro avg       0.72      0.77      0.74       441\n",
      "weighted avg       0.81      0.77      0.78       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Sequential Model results\n",
    "print(classification_report(y_test, y_preds_unpad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
