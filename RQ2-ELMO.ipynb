{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: https://github.com/arunarn2/HierarchicalAttentionNetworks/blob/master/HierarchicalAttn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Input, load_model\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Lambda\n",
    "from keras.optimizers import RMSprop, Adam, Adamax, SGD\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import add\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score as scikit_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.callbacks import PlotCurves\n",
    "from src.eval_metrics_seq import f1_macro, f1_micro\n",
    "from src.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, metadata = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 60\n",
    "n_tags = 2\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(data_, max_len, n_tags, is_test=False, limit=None):\n",
    "    \n",
    "    # limit data if not an even number when batch_size=2\n",
    "    if not limit:\n",
    "        limit = len(data_) if len(data_)%2 == 0 else len(data_)-1\n",
    "\n",
    "    data_ = data_[:limit]\n",
    "    \n",
    "    X = []\n",
    "    for article in data_:\n",
    "        new_seq = []\n",
    "        for i in range(max_len):\n",
    "            try:\n",
    "                new_seq.append(article['sentences'][i]['sentence'].replace('\\n', '').strip())\n",
    "            except:\n",
    "                new_seq.append(\"ENDPAD\")\n",
    "        X.append(new_seq)\n",
    "    \n",
    "    if not is_test: \n",
    "        y = [[sent['label'] for sent in article['sentences']] for article in data_]\n",
    "        y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=0)\n",
    "        y = [[to_categorical(lab, num_classes=n_tags) for lab in sent] for sent in y]\n",
    "    else:\n",
    "        y = [sent['label'] for article in data_ for sent in article['sentences']]\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra, y_tra = get_input(train_data, max_len, n_tags, False)\n",
    "X_val, y_val = get_input(valid_data, max_len, n_tags, False, limit=2)\n",
    "X_test, y_test = get_input(test_data, max_len, n_tags, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250, 60), (2, 60), (32, 60))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tra.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250, 60, 2), (2, 60, 2), (441,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tra.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELMoEmbeddingStack(x):\n",
    "    embeds = []\n",
    "    for art in tf.unstack(tf.transpose(x, (1, 0))):\n",
    "        embeds.append(elmo(tf.squeeze(tf.cast(art, tf.string)), signature=\"default\", as_dict=True)[\"default\"])\n",
    "    return tf.stack(embeds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_0(max_len, n_tags):\n",
    "    \n",
    "    def residual(x):\n",
    "        x_res = x\n",
    "        \n",
    "        x = Bidirectional(LSTM(units=128, return_sequences=True,\n",
    "                               recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "        x = add([x, x_res])\n",
    "        return x\n",
    "    \n",
    "    input_text = Input(shape=(max_len,), dtype=\"string\")\n",
    "    \n",
    "    embedding = Lambda(ELMoEmbeddingStack, output_shape=(None, None, max_len, 1024))(input_text)\n",
    "    \n",
    "    x = Dense(512, activation='relu')(embedding)\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    x = Bidirectional(LSTM(units=128, return_sequences=True,\n",
    "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "    x = residual(x)\n",
    "\n",
    "    pred = TimeDistributed(Dense(n_tags, activation=\"sigmoid\"))(x)\n",
    "\n",
    "    return Model(inputs=[input_text], outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1(max_len, n_tags):\n",
    "    \n",
    "    def residual(x):\n",
    "        x_res = x\n",
    "        \n",
    "        x = Bidirectional(LSTM(units=256, return_sequences=True,\n",
    "                               recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "        x = add([x, x_res])\n",
    "        return x\n",
    "    \n",
    "    input_text = Input(shape=(max_len,), dtype=\"string\")\n",
    "    \n",
    "    embedding = Lambda(ELMoEmbeddingStack, output_shape=(None, None, max_len, 1024))(input_text)\n",
    "    \n",
    "    x = Bidirectional(LSTM(units=256, return_sequences=True,\n",
    "                           recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
    "    x = residual(x)\n",
    "\n",
    "    pred = TimeDistributed(Dense(n_tags, activation=\"sigmoid\"))(x)\n",
    "\n",
    "    return Model(inputs=[input_text], outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrate=0.0001\n",
    "optimizer = Adam(lr=learningrate)\n",
    "optimizer_str = 'adam'\n",
    "loss = 'binary_crossentropy'\n",
    "metrics = ['acc', f1_macro, f1_micro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 19:49:20.426137 139877238231168 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/Master_Thesis/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0911 19:49:20.427018 139877238231168 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/Master_Thesis/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0911 19:49:43.994876 139877238231168 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/Master_Thesis/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0911 19:49:44.186916 139877238231168 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/Master_Thesis/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0911 19:49:44.193013 139877238231168 deprecation.py:506] From /home/aorus/workspaces/simge/Master_Thesis/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0911 19:49:45.037700 139877238231168 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/Master_Thesis/.env/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0911 19:49:45.041514 139877238231168 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/Master_Thesis/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0911 19:49:45.043634 139877238231168 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/Master_Thesis/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3378: The name tf.nn.sigmoid_cross_entropy_with_logits is deprecated. Please use tf.nn.sigmoid_cross_entropy_with_logits instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, None, 6 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 512)    2623488     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 512)    1574912     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 512)    0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 2)      1026        add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 4,199,426\n",
      "Trainable params: 4,199,426\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model_1(max_len, n_tags)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'RQ2_test_elmo_model_1' + \\\n",
    "             '_maxlen_' + str(max_len) + \\\n",
    "             '_' + optimizer_str + \\\n",
    "             '_lr_' + str(learningrate) + \\\n",
    "             '_lrreduction' + \\\n",
    "             '_loss_' + loss\n",
    "\n",
    "model_dir = './Model/' + model_name.split('model')[0] + 'model/' + model_name\n",
    "results_file = os.path.join(model_dir, 'model_results_file.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 2 samples\n",
      "Epoch 1/50\n",
      "248/250 [============================>.] - ETA: 1s - loss: 0.1473 - acc: 0.9343 - f1_macro: 0.5643 - f1_micro: 0.9322"
     ]
    }
   ],
   "source": [
    "model.fit(X_tra, y_tra, \n",
    "          epochs=50, \n",
    "          batch_size=batch_size, \n",
    "          validation_data=(X_val, y_val), \n",
    "          callbacks=[\n",
    "              PlotCurves(model_name=model_name, model_dir=model_dir, jnote=True),\n",
    "              ReduceLROnPlateau(monitor='val_f1_macro', patience=3, \n",
    "                                factor=0.1, min_lr=0.00001),\n",
    "              EarlyStopping(monitor='val_f1_macro', min_delta=0, patience=5, mode='max')\n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RQ2_test_elmo_model_0__maxlen_60_adam_lr_0.0001_lrreduction_loss_binary_crossentropy'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(os.path.join(model_dir, model_name + '_best_f1_macro_model.h5'), \n",
    "                        custom_objects={'elmo':elmo, 'tf':tf, 'f1_macro':f1_macro, 'f1_micro':f1_micro})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model, data_, batch_size, max_len, n_tags, results_file, print_out=False):\n",
    "    \n",
    "    def unpad(X, y_preds):\n",
    "        y_unpad = []\n",
    "        for ai, art in enumerate(X):\n",
    "            for si, sent in enumerate(art):\n",
    "                if sent != 'ENDPAD':\n",
    "                    y_unpad.append(y_preds[ai][si])\n",
    "        return y_unpad\n",
    "    \n",
    "    X, y = get_input(data_, max_len, n_tags, True)\n",
    "    \n",
    "    y_preds = model.predict(X, batch_size=batch_size)\n",
    "    y_preds = unpad(X, y_preds)\n",
    "    y_preds = np.argmax(y_preds, axis=1)\n",
    "    \n",
    "    clsrpt = classification_report(y, y_preds)\n",
    "    sfm = scikit_f1_score(y, y_preds, average='macro')\n",
    "    \n",
    "    if print_out:\n",
    "        print(clsrpt)\n",
    "        print('\\nScikit_F1_Macro:', sfm)\n",
    "\n",
    "    if results_file:\n",
    "        with open(results_file, 'a') as f:\n",
    "            f.write('\\n' + clsrpt + '\\n' + str(sfm) + '\\n')\n",
    "            \n",
    "    return sfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       269\n",
      "           1       0.76      0.74      0.75       130\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       399\n",
      "   macro avg       0.82      0.81      0.82       399\n",
      "weighted avg       0.84      0.84      0.84       399\n",
      "\n",
      "\n",
      "Scikit_F1_Macro: 0.815959409594096\n"
     ]
    }
   ],
   "source": [
    "with open(results_file, 'w') as f:\n",
    "    f.write('\\n---------------- Validation ----------------\\n')\n",
    "val_f1 = get_scores(best_model, valid_data, batch_size, max_len, n_tags, results_file, print_out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       325\n",
      "           1       0.75      0.43      0.55       116\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       441\n",
      "   macro avg       0.78      0.69      0.71       441\n",
      "weighted avg       0.80      0.81      0.79       441\n",
      "\n",
      "\n",
      "Scikit_F1_Macro: 0.7138535143882361\n"
     ]
    }
   ],
   "source": [
    "with open(results_file, 'a') as f:\n",
    "    f.write('\\n---------------- Test ----------------\\n')\n",
    "test_f1 = get_scores(best_model, test_data, batch_size, max_len, n_tags, results_file, print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       325\n",
      "           1       0.54      0.72      0.62       116\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       441\n",
      "   macro avg       0.71      0.75      0.72       441\n",
      "weighted avg       0.80      0.76      0.77       441\n",
      "\n",
      "\n",
      "Scikit_F1_Macro: 0.7235776277724204\n"
     ]
    }
   ],
   "source": [
    "# Onceden cok onceden\n",
    "with open(results_file, 'a') as f:\n",
    "    f.write('\\n---------------- Test ----------------\\n')\n",
    "test_f1 = get_scores(best_model, test_data, batch_size, max_len, n_tags, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
